{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6019965",
   "metadata": {},
   "source": [
    "### Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d74b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import json\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda06593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9437c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a0f1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Selecting the device\n",
    "device = torch.device(\"cuda:1\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850063b0",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95cfb142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([9, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai4bharat/indicNER\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39mnum_labels)\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai4bharat/indicNER\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai4bharat/indicNER\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39mnum_labels )\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/env1/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/env1/lib/python3.12/site-packages/transformers/modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3495\u001b[0m     (\n\u001b[1;32m   3496\u001b[0m         model,\n\u001b[1;32m   3497\u001b[0m         missing_keys,\n\u001b[1;32m   3498\u001b[0m         unexpected_keys,\n\u001b[1;32m   3499\u001b[0m         mismatched_keys,\n\u001b[1;32m   3500\u001b[0m         offload_index,\n\u001b[1;32m   3501\u001b[0m         error_msgs,\n\u001b[0;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_pretrained_model(\n\u001b[1;32m   3503\u001b[0m         model,\n\u001b[1;32m   3504\u001b[0m         state_dict,\n\u001b[1;32m   3505\u001b[0m         loaded_state_dict_keys,  \u001b[38;5;66;03m# XXX: rename?\u001b[39;00m\n\u001b[1;32m   3506\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3507\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3508\u001b[0m         ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[1;32m   3509\u001b[0m         sharded_metadata\u001b[38;5;241m=\u001b[39msharded_metadata,\n\u001b[1;32m   3510\u001b[0m         _fast_init\u001b[38;5;241m=\u001b[39m_fast_init,\n\u001b[1;32m   3511\u001b[0m         low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[1;32m   3512\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   3513\u001b[0m         offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   3514\u001b[0m         offload_state_dict\u001b[38;5;241m=\u001b[39moffload_state_dict,\n\u001b[1;32m   3515\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[1;32m   3516\u001b[0m         hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[1;32m   3517\u001b[0m         keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   3518\u001b[0m     )\n\u001b[1;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/env1/lib/python3.12/site-packages/transformers/modeling_utils.py:3977\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[1;32m   3974\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3975\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3976\u001b[0m         )\n\u001b[0;32m-> 3977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3980\u001b[0m     archs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([9, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "# IndicNER\n",
    "num_labels = 9\n",
    "text_name = \"words\"\n",
    "label_name = \"ner\"\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indicNER', num_labels=num_labels)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicNER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indicNER', num_labels=num_labels )\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2b0d5",
   "metadata": {},
   "source": [
    "The above code explains that we cannot modify the number of labels for IndicNER, as it is already fine-tuned with NER task, and does not add any additional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f1fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IndicNER\n",
    "num_labels = 7\n",
    "text_name = \"words\"\n",
    "label_name = \"ner\"\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indicNER')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicNER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indicNER' )\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd591d",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450e5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_dict = {\n",
    "    'O' : 0,\n",
    "    'B-PER' : 1,\n",
    "    'I-PER' : 2,\n",
    "    'B-ORG' : 3,\n",
    "    'I-ORG' : 4,\n",
    "    'B-LOC' : 5,\n",
    "    'I-LOC' : 6,\n",
    "    'B-MISC': 7, # Adding the extra two label will help to use the compute metric of the trainer\n",
    "    'I-MISC' : 8 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864b515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_label = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdf0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset( file_path, text_name = text_name, label_name = label_name, dataset_type = None, \n",
    "                 num_samples_to_take = None ):\n",
    "    \n",
    "    data_dir = { text_name : [ ], label_name : [ ] }\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data_dir[text_name].append(json.loads(line)[text_name])\n",
    "            data_dir[label_name].append( [ label_to_id_dict[i] for i in ( json.loads(line)[label_name] ) ] )\n",
    "    if dataset_type == 'train':\n",
    "        # For sampling the initial 20000 samples\n",
    "        data_dir[text_name] = data_dir[text_name][0:num_samples_to_take]\n",
    "        data_dir[label_name] = data_dir[label_name][ 0:num_samples_to_take]\n",
    "    data = Dataset.from_dict(data_dir)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ad1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = make_dataset(\"./bn_IndicNER_v1.0/bn_train.json\", dataset_type = \"train\", num_samples_to_take=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ecb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = make_dataset(\"./bn_IndicNER_v1.0/bn_val.json\", num_samples_to_take=100)\n",
    "test_data = make_dataset(\"./bn_IndicNER_v1.0/bn_test.json\", num_samples_to_take=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b078ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577fab30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 4859\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7701999",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = \"max_length\"\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the text and match the target label with the text token\n",
    "    Input: A batch of sentence\n",
    "        A dict:\n",
    "            'words': A list of sentences denoted as a list of words\n",
    "                        Desired Input to the model\n",
    "            'ner': A list of desired labels\n",
    "    Output: Tokenized Sentence\n",
    "        A dict: dict:\n",
    "            'words': A list of sentences denoted as a list of words\n",
    "                        Desired Input to the model\n",
    "            'ner': A list of desired labels\n",
    "            'input_ids': Id of the tokenized words\n",
    "                            A list of sentences denoted as \n",
    "                            a list of Id s of the consitituted word tokens\n",
    "                            # Input to the Transformer model\n",
    "            'attention_masks': A binary list\n",
    "                                1 indicates the text token, model will attend to\n",
    "                                0 indicates the padding token and special token, the model will not attend to.\n",
    "            'labels': A list of numbers\n",
    "                        Denting the target ground truth label\n",
    "                        generated from the 'ner' field of Input\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_name]):\n",
    "        \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc0ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:05<00:00, 3432.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c833e947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the toenized data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9544669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on validation dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4859/4859 [00:01<00:00, 3517.49 examples/s]\n",
      "Running tokenizer on test dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 607/607 [00:00<00:00, 3602.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_data = val_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on test dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fafecd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27872efd",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b724219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1876914/2858202782.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_2_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_2_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58557501",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfdec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(batch_size, lr , model, train_data = train_data, val_data = val_data,\n",
    "                  tokenizer = tokenizer, data_collator = data_collator, compute_metrics = compute_metrics):\n",
    "                    \n",
    "    \n",
    "    \n",
    "    # Setting the TrainingArguments\n",
    "    args=TrainingArguments(\n",
    "        output_dir='output_dir',\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate = lr,\n",
    "        num_train_epochs = 3 # As asked in the question\n",
    "        )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        args=args,\n",
    "    )\n",
    "    \n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    eval_metric = trainer.evaluate(val_data)\n",
    "    \n",
    "    return (trainer, train_result, eval_metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1902ce",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee930dd",
   "metadata": {},
   "source": [
    "We have tuned the batch size and learning-rate as two are the most important hyper-parameters. \n",
    "Batch Size: Larger Batch size might result in a smoother convergence during Gradient descent, with a huge cost of calculating the gradients. Whereas smaller batch size might result ina more haphazard convergence but each step of Gradient Descent is fast. Therefore a we need to fine tune the optimum.\n",
    "\n",
    "Learning Rate: A Higher Learning Rate indicates larger step, which might lead the model to go in bad optima, and lower earning rate might not help the model to converge.\n",
    "\n",
    "We use a random sapling approach and done only 3 experiments due to limited resources for Hyper-parameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15ca8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_search():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indicNER' )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    tunable_hyper_param = {'batch_size' : [8, 16, 32],\n",
    "                      'lr': [1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "    batch_size = tunable_hyper_param['batch_size'][random.randint(0,2)] \n",
    "                # Generating a random number between 0 and 2 (both included)\n",
    "    lr = tunable_hyper_param['lr'][random.randint(0,3)]\n",
    "                # Generating a random number between 0 and 3 (both included)\n",
    "    \n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9195a",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f93c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "32 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 07:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "(trainer, train_result, eval_metric, batch_size, lr) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2caf6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 32, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7981597781181335,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187198114551364,\n",
       " 'eval_runtime': 24.6876,\n",
       " 'eval_samples_per_second': 196.82,\n",
       " 'eval_steps_per_second': 6.157,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size, lr))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879206d",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0c47a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "32 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 07:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(trainer_2, train_result_2, eval_metric_2, batch_size_2, lr_2) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "333995b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 32, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7981597781181335,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187198114551364,\n",
       " 'eval_runtime': 24.9677,\n",
       " 'eval_samples_per_second': 194.611,\n",
       " 'eval_steps_per_second': 6.088,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_2, lr_2))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ee78a",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45c49fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "32 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 07:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "(trainer_3, train_result_3, eval_metric_3, batch_size_3, lr_3) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d4c7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 32, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7981597781181335,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187198114551364,\n",
       " 'eval_runtime': 25.1842,\n",
       " 'eval_samples_per_second': 192.939,\n",
       " 'eval_steps_per_second': 6.036,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_3, lr_3))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d80aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_setting():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indicNER' )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    batch_size = 8\n",
    "    lr = 1e-5\n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be09c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "8 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 11:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.156400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='968' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 13:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(trainer_4, train_result_4, eval_metric_4, batch_size_4, lr_4) = hyper_param_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fdc8ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 8, and Learning Rate = 1e-05 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19311270117759705,\n",
       " 'eval_LOC_precision': 0.7546480743691899,\n",
       " 'eval_LOC_recall': 0.8086090359302739,\n",
       " 'eval_LOC_f1': 0.7806972351021809,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.6146688560481663,\n",
       " 'eval_ORG_recall': 0.6413478012564249,\n",
       " 'eval_ORG_f1': 0.6277249860257126,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.8009319181982915,\n",
       " 'eval_PER_recall': 0.8366684694429422,\n",
       " 'eval_PER_f1': 0.8184102631926993,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.745805561939784,\n",
       " 'eval_overall_recall': 0.7857142857142857,\n",
       " 'eval_overall_f1': 0.7652399481193256,\n",
       " 'eval_overall_accuracy': 0.9458969478005258,\n",
       " 'eval_runtime': 25.2989,\n",
       " 'eval_samples_per_second': 192.063,\n",
       " 'eval_steps_per_second': 6.008,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_4, lr_4))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd79a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_setting_2():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    batch_size = 16\n",
    "    lr = 1e-6\n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f810eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "16 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 06:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.933500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 12:03:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 16, and Learning Rate = 1e-06 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7791699171066284,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187198114551364,\n",
       " 'eval_runtime': 17.4745,\n",
       " 'eval_samples_per_second': 278.062,\n",
       " 'eval_steps_per_second': 8.698,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainer_5, train_result_5, eval_metric_5, batch_size_5, lr_5) = hyper_param_setting_2()\n",
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_5, lr_5))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35c1a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_4.model.save_pretrained(\"./IndicNER_trainer_4\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07b52d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_5.model.save_pretrained(\"./IndicNER_trainer_5\", from_pt = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171422ba",
   "metadata": {},
   "source": [
    "### Calculating Macro-F1 for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10f1a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trainer_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b68fbed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric = best_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "341fffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.model.save_pretrained(\"./IndicBERT_best\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b305a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.16460365056991577,\n",
       " 'eval_LOC_precision': 0.7739938080495357,\n",
       " 'eval_LOC_recall': 0.7552870090634441,\n",
       " 'eval_LOC_f1': 0.7645259938837919,\n",
       " 'eval_LOC_number': 331,\n",
       " 'eval_ORG_precision': 0.7116279069767442,\n",
       " 'eval_ORG_recall': 0.7391304347826086,\n",
       " 'eval_ORG_f1': 0.7251184834123222,\n",
       " 'eval_ORG_number': 207,\n",
       " 'eval_PER_precision': 0.8315789473684211,\n",
       " 'eval_PER_recall': 0.8605664488017429,\n",
       " 'eval_PER_f1': 0.8458244111349036,\n",
       " 'eval_PER_number': 459,\n",
       " 'eval_overall_precision': 0.7877591312931885,\n",
       " 'eval_overall_recall': 0.8004012036108324,\n",
       " 'eval_overall_f1': 0.7940298507462685,\n",
       " 'eval_overall_accuracy': 0.9548401774542146,\n",
       " 'eval_runtime': 3.2695,\n",
       " 'eval_samples_per_second': 185.657,\n",
       " 'eval_steps_per_second': 5.811,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d745cec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19311270117759705,\n",
       " 'eval_LOC_precision': 0.7546480743691899,\n",
       " 'eval_LOC_recall': 0.8086090359302739,\n",
       " 'eval_LOC_f1': 0.7806972351021809,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.6146688560481663,\n",
       " 'eval_ORG_recall': 0.6413478012564249,\n",
       " 'eval_ORG_f1': 0.6277249860257126,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.8009319181982915,\n",
       " 'eval_PER_recall': 0.8366684694429422,\n",
       " 'eval_PER_f1': 0.8184102631926993,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.745805561939784,\n",
       " 'eval_overall_recall': 0.7857142857142857,\n",
       " 'eval_overall_f1': 0.7652399481193256,\n",
       " 'eval_overall_accuracy': 0.9458969478005258,\n",
       " 'eval_runtime': 24.9836,\n",
       " 'eval_samples_per_second': 194.487,\n",
       " 'eval_steps_per_second': 6.084,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric = best_model.evaluate(val_data)\n",
    "val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab02643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11506272107362747,\n",
       " 'eval_LOC_precision': 0.8161290322580645,\n",
       " 'eval_LOC_recall': 0.8566591422121896,\n",
       " 'eval_LOC_f1': 0.8359030837004405,\n",
       " 'eval_LOC_number': 11518,\n",
       " 'eval_ORG_precision': 0.7471780225758194,\n",
       " 'eval_ORG_recall': 0.7658210203512684,\n",
       " 'eval_ORG_f1': 0.7563846630412335,\n",
       " 'eval_ORG_number': 7174,\n",
       " 'eval_PER_precision': 0.8539766157008866,\n",
       " 'eval_PER_recall': 0.8851967769860825,\n",
       " 'eval_PER_f1': 0.8693064774547953,\n",
       " 'eval_PER_number': 15017,\n",
       " 'eval_overall_precision': 0.8184752492216287,\n",
       " 'eval_overall_recall': 0.8500400486516954,\n",
       " 'eval_overall_f1': 0.8339590791350155,\n",
       " 'eval_overall_accuracy': 0.9645699033037872,\n",
       " 'eval_runtime': 103.5324,\n",
       " 'eval_samples_per_second': 193.176,\n",
       " 'eval_steps_per_second': 6.037,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metric = best_model.evaluate(train_data)\n",
    "train_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9cb5b2",
   "metadata": {},
   "source": [
    "### Load the Manually Annotated Data and Calc the Macro-F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d08f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_corpus_label_from_manual_anno(text):\n",
    "    \"\"\"\n",
    "    Modify the annotated label, such that model can use it as Tags\n",
    "    \"\"\"\n",
    "    text_1 = text.split(' ')\n",
    "    new_text = []\n",
    "    new_id = []\n",
    "    for word in text_1:\n",
    "        if word == '[' or word == ']' or word == ',' or word == '\"' or word == '\\n' or word == ' ' or word == '':\n",
    "            pass\n",
    "        else:\n",
    "            n_w = ''\n",
    "            for i in word:\n",
    "                if i == '[' or i == ']' or i == ',' or i == '\"' or i == '\\n' or i == '\\'':\n",
    "                    pass\n",
    "                else:\n",
    "                    n_w = n_w + i\n",
    "            if n_w != '':\n",
    "                new_text.append(n_w)\n",
    "                id1 = label_to_id_dict[n_w]\n",
    "                if id1 == 7 or id1 == 8:\n",
    "                    id1 = 0\n",
    "                new_id.append(id1)\n",
    "    return (new_id, new_text)\n",
    "\n",
    "\n",
    "i = 0\n",
    "text_corpus = {'words':[],\n",
    "              'ner' : []}\n",
    "with open(\"annotated_text.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if i % 3 == 0:\n",
    "            text = line\n",
    "            text_1 = text.split(\" \")[1:]\n",
    "            if text_1[-1] == '\\n':\n",
    "                text_1 = text_1[0:-1]\n",
    "            text_corpus['words'].append(text_1)\n",
    "        elif i % 3 == 1:\n",
    "            label = line\n",
    "            ( new_label_id, new_label ) = form_corpus_label_from_manual_anno(label)\n",
    "            text_corpus['ner'].append(new_label_id)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c443c36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': [['à¦°à¦¾à¦¤',\n",
       "   'à¦¸à¦¾à§œà§‡',\n",
       "   'à¦†à¦Ÿà¦Ÿà¦¾à¦¤à§‡à¦“',\n",
       "   'à¦“à¦•à§‡',\n",
       "   'à¦à¦•à¦¾',\n",
       "   'à¦°à¦¿à¦•à¦¶à¦¾à§Ÿ',\n",
       "   'à¦›à§‡à§œà§‡',\n",
       "   'à¦¦à¦¿à¦¤à§‡',\n",
       "   'à¦¤à¦¿à¦¨à¦¿',\n",
       "   'à¦°à¦¾à¦œà¦¿',\n",
       "   'à¦¨à¦¨à¥¤\\n'],\n",
       "  ['à¦à¦•à¦¾à¦§à¦¿à¦•',\n",
       "   'à¦œà¦™à§à¦—à¦¿',\n",
       "   'à¦˜à¦¾à¦à¦Ÿà¦¿',\n",
       "   'à¦§à§à¦¬à¦‚à¦¸',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¦à§‡à¦“à§Ÿà¦¾',\n",
       "   'à¦¹à§Ÿà§‡à¦›à§‡',\n",
       "   'à¦¬à¦²à§‡',\n",
       "   'à¦¦à¦¾à¦¬à¦¿',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¸à¦°à¦•à¦¾à¦°à¥¤\\n'],\n",
       "  ['à¦',\n",
       "   'à¦¸à¦®à§à¦®à§‡à¦²à¦¨à§‡',\n",
       "   'à¦¬à¦¿à¦¶à§à¦¬à§‡à¦°',\n",
       "   'à¦ªà§à¦°à¦¾à§Ÿ',\n",
       "   'à¦¦à§‡à§œ',\n",
       "   'à¦¹à¦¾à¦œà¦¾à¦°',\n",
       "   'à¦¨à¦¾à¦°à§€',\n",
       "   'à¦¨à§‡à¦¤à§ƒà¦¤à§à¦¬',\n",
       "   'à¦¯à§‹à¦—à¦¦à¦¾à¦¨',\n",
       "   'à¦•à¦°à§‡à¦¨à¥¤\\n'],\n",
       "  ['à¦†à¦¬à§à¦¦à§à¦²',\n",
       "   'à¦®à¦¾à¦²à§‡à¦•',\n",
       "   'à¦¹à¦¿à¦®à§,',\n",
       "   'à¦…à¦ªà§',\n",
       "   'à¦†à¦²à¦®,',\n",
       "   'à¦¦à¦¬à¦¿à¦°',\n",
       "   'à¦®à§‹à¦¹à¦¾à¦®à§à¦®à¦¦',\n",
       "   'à¦¸à¦¹',\n",
       "   'à¦†à¦°à§‹',\n",
       "   'à¦…à¦¨à§‡à¦•à§‡à¥¤\\n'],\n",
       "  ['à¦®à¦¿à¦¥à¦¿à¦²à¦¾',\n",
       "   'à¦¯à§‡',\n",
       "   'à¦…à¦¨à¦¿à¦•à§‡à¦°',\n",
       "   'à¦à¦‡',\n",
       "   'à¦œà¦¿à¦¨à¦¿à¦¸à¦—à§à¦²à§‹',\n",
       "   'à¦œà¦¾à¦¨à§‡',\n",
       "   'à¦¨à¦¾',\n",
       "   'à¦¤à¦¾',\n",
       "   'à¦¨à§Ÿà¥¤',\n",
       "   'à¦•à¦¿à¦¨à§à¦¤à§',\n",
       "   'à¦¸à§‡',\n",
       "   'à¦šà¦¾à§Ÿ',\n",
       "   'à¦¯à§‡',\n",
       "   'à¦…à¦¨à¦¿à¦•',\n",
       "   'à¦¸à¦¬',\n",
       "   'à¦¸à¦®à§Ÿ',\n",
       "   'à¦¤à¦¾à¦°',\n",
       "   'à¦•à¦¾à¦›à§‡',\n",
       "   'à¦¸à¦¤à§à¦¯à¦¿',\n",
       "   'à¦•à¦¥à¦¾',\n",
       "   'à¦¬à¦²à§à¦•à¥¤'],\n",
       "  ['à¦²à§‹à¦•à¦¸à¦­à¦¾à¦°',\n",
       "   'à¦¸à§à¦ªà¦¿à¦•à¦¾à¦°',\n",
       "   'à¦“à¦®',\n",
       "   'à¦¬à¦¿à¦¡à¦¼à¦²à¦¾à¦°',\n",
       "   'à¦ªà§à¦°à¦¸à§à¦¤à¦¾à¦¬à§‡',\n",
       "   'à¦¸à¦®à§à¦®à¦¤à¦¿',\n",
       "   'à¦œà¦¾à¦¨à¦¿à§Ÿà§‡à¦›à§‡à¦¨',\n",
       "   'à¦¸à¦¬',\n",
       "   'à¦¦à¦²à§‡à¦°',\n",
       "   'à¦¸à¦¾à¦‚à¦¸à¦¦à¦°à¦¾à¥¤\\n'],\n",
       "  ['à¦®à¦¿à¦¥à¦¿à¦²à¦¾', 'à¦šà§à¦ª', 'à¦•à¦°à§‡', 'à¦¶à§à¦¨à§‡', 'à¦—à§‡à¦²à§‡à¦“', 'à¦®à§à¦–à§‡', 'à¦•à¦¿à¦›à§', 'à¦¬à¦²à¦²', 'à¦¨à¦¾à¥¤'],\n",
       "  ['à¦œà¦¾à¦¨à¦¾',\n",
       "   'à¦¯à¦¾à§Ÿ,',\n",
       "   'à¦œà¦—à¦¨à§à¦¨à¦¾à¦¥à¦ªà§à¦°',\n",
       "   'à¦ªà§Œà¦°',\n",
       "   'à¦¶à¦¹à¦°à§‡à¦°',\n",
       "   'à¦›à¦¿à¦²à¦¿à¦®à¦ªà§à¦°',\n",
       "   'à¦—à§à¦°à¦¾à¦®à§‡à¦°',\n",
       "   'à¦ªà§à¦°à§Ÿà¦¾à¦¤',\n",
       "   'à¦¶à¦¾à¦²à¦¿à¦¸à¦¿',\n",
       "   'à¦¬à§à¦¯à¦•à§à¦¤à¦¿',\n",
       "   'à¦¹à¦¾à¦œà§€',\n",
       "   'à¦«à¦¿à¦°à§‹à¦œ',\n",
       "   'à¦®à¦¿à§Ÿà¦¾à¦°',\n",
       "   'à¦¬à¦¿à¦ªà§à¦²',\n",
       "   'à¦ªà¦°à¦¿à¦®à¦¾à¦£',\n",
       "   'à¦œà¦¾à§Ÿà¦—à¦¾',\n",
       "   'à¦¸à¦®à§à¦ªà¦¤à§à¦¤à¦¿',\n",
       "   'à¦°à§Ÿà§‡à¦›à§‡à¥¤'],\n",
       "  ['à¦ªà§à¦²à¦¿à¦¶',\n",
       "   'à¦¸à§à¦ªà¦¾à¦°',\n",
       "   'à¦¶à§à¦¯à¦¾à¦®à¦²',\n",
       "   'à¦•à§à¦®à¦¾à¦°',\n",
       "   'à¦¨à¦¾à¦¥',\n",
       "   'à¦œà¦¾à¦¨à¦¾à¦¨,',\n",
       "   'à¦œà¦®à¦¿à¦¸à¦‚à¦•à§à¦°à¦¾à¦¨à§à¦¤',\n",
       "   'à¦¬à¦¿à¦·à§Ÿ',\n",
       "   'à¦¨à¦¿à§Ÿà§‡',\n",
       "   'à¦à¦‡',\n",
       "   'à¦¹à¦¾à¦®à¦²à¦¾',\n",
       "   'à¦¹à§Ÿà§‡à¦›à§‡à¥¤'],\n",
       "  ['à¦',\n",
       "   'à¦›à¦¬à¦¿à¦¤à§‡',\n",
       "   'à¦¸à¦²à¦®à¦¨',\n",
       "   'à¦–à¦¾à¦¨à¦•à§‡',\n",
       "   'à¦à¦•',\n",
       "   'à¦¸à¦¾à¦§à¦¾à¦°à¦£',\n",
       "   'à¦¨à¦¾à¦—à¦°à¦¿à¦•à§‡à¦°',\n",
       "   'à¦šà¦°à¦¿à¦¤à§à¦°à§‡',\n",
       "   'à¦¦à§‡à¦–à¦¾',\n",
       "   'à¦¯à¦¾à¦¬à§‡à¥¤\\n'],\n",
       "  ['à¦à¦•à¦¾à¦¦à¦¶',\n",
       "   'à¦œà¦¾à¦¤à§€à§Ÿ',\n",
       "   'à¦¸à¦‚à¦¸à¦¦',\n",
       "   'à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨à§‡',\n",
       "   'à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¿à¦¤',\n",
       "   'à§¨à§¯à§¦',\n",
       "   'à¦¸à¦¾à¦‚à¦¸à¦¦à§‡à¦°',\n",
       "   'à¦ªà¦¦à§‡',\n",
       "   'à¦¥à¦¾à¦•à¦¾à¦°',\n",
       "   'à¦¬à§ˆà¦§à¦¤à¦¾',\n",
       "   'à¦¨à¦¿à§Ÿà§‡',\n",
       "   'à¦•à¦°à¦¾',\n",
       "   'à¦°à¦¿à¦Ÿà¦Ÿà¦¿',\n",
       "   'à¦¸à¦°à¦¾à¦¸à¦°à¦¿',\n",
       "   'à¦–à¦¾à¦°à¦¿à¦œ',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¦à¦¿à§Ÿà§‡à¦›à§‡à¦¨',\n",
       "   'à¦¹à¦¾à¦‡à¦•à§‹à¦°à§à¦Ÿà¥¤\\n'],\n",
       "  ['à¦Ÿà¦¾à¦•à¦¾',\n",
       "   'à¦›à¦¿à¦²',\n",
       "   'à¦¨à¦¾',\n",
       "   'à¦¬à¦²à§‡',\n",
       "   'à¦œà¦¿à¦¨à¦¿à¦¸à¦ªà¦¤à§à¦°',\n",
       "   'à¦«à§‡à¦°à¦¿',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¬à§‡à§œà¦¾à¦¨à§‹,',\n",
       "   'à¦¦à§‹à¦•à¦¾à¦¨',\n",
       "   'à¦¦à§‡à¦“à§Ÿà¦¾,',\n",
       "   'à¦¥à¦¾à¦•à¦¾-à¦–à¦¾à¦“à§Ÿà¦¾à¦°',\n",
       "   'à¦¬à¦¿à¦¨à¦¿à¦®à§Ÿà§‡',\n",
       "   'à¦¨à¦¬à¦¿à¦¶à¦¿',\n",
       "   'à¦•à¦¿à¦‚à¦¬à¦¾',\n",
       "   'à¦¸à¦®à¦¾à¦œà§‡à¦°',\n",
       "   'à¦‰à¦à¦šà§à¦¤à¦²à¦¾à¦°',\n",
       "   'à¦œà¦¨à§à¦¯',\n",
       "   'à¦¸à¦¨à§à¦¨à§à¦¯à¦¾à¦¸à¦¿à¦¨à§€',\n",
       "   'à¦¹à¦“à§Ÿà¦¾â€”à¦à¦¸à¦¬',\n",
       "   'à¦¬à¦¾à¦¤à¦¿à¦²',\n",
       "   'à¦¹à§Ÿà§‡',\n",
       "   'à¦—à§‡à¦²à¥¤\\n'],\n",
       "  ['à¦•à¦¾à¦°à¦£',\n",
       "   'à¦¸à§‡',\n",
       "   'à¦¨à¦¿à¦œà§‡',\n",
       "   'à¦•à¦¾à¦²',\n",
       "   'à¦…à¦¨à¦¿à¦•à¦•à§‡',\n",
       "   'à¦¶à¦ªà¦¿à¦‚',\n",
       "   'à¦®à¦²à§‡',\n",
       "   'à¦à¦•à¦Ÿà¦¾',\n",
       "   'à¦®à§‡à§Ÿà§‡à¦°',\n",
       "   'à¦¸à¦¾à¦¥à§‡',\n",
       "   'à¦¦à§‡à¦–à§‡à¦›à§‡à¥¤'],\n",
       "  ['à¦®à§‡à§Ÿà§‡à¦Ÿà¦¿',\n",
       "   'à¦¯à¦¾à¦¤à§‡',\n",
       "   'à¦¬à¦¿à¦¨à¦¾',\n",
       "   'à¦®à§‚à¦²à§à¦¯à§‡',\n",
       "   'à¦²à§‡à¦–à¦¾à¦ªà¦¡à¦¼à¦¾à¦°',\n",
       "   'à¦¸à§à¦¯à§‹à¦—',\n",
       "   'à¦ªà¦¾à§Ÿ,',\n",
       "   'à¦¸à§‡',\n",
       "   'à¦¬à§à¦¯à¦¬à¦¸à§à¦¥à¦¾à¦“',\n",
       "   'à¦¸à¦°à¦•à¦¾à¦°à¦•à§‡à¦‡',\n",
       "   'à¦•à¦°à¦¤à§‡',\n",
       "   'à¦¹à¦¬à§‡à¥¤\\n'],\n",
       "  ['à¦œà¦¾à¦¨à¦¾',\n",
       "   'à¦—à§‡à¦›à§‡,',\n",
       "   'à¦¬à¦¿à¦ªà¦¿à¦à¦²à§‡à¦°',\n",
       "   'à¦‰à¦¦à§à¦¬à§‹à¦§à¦¨à§€',\n",
       "   'à¦…à¦¨à§à¦·à§à¦ à¦¾à¦¨à§‡',\n",
       "   'à¦¸à¦¾à¦²à¦®à¦¾à¦¨',\n",
       "   'à¦–à¦¾à¦¨',\n",
       "   'à¦¨à¦¾à¦•à¦¿',\n",
       "   'à¦¶à§à¦°à§à¦¤à§‡',\n",
       "   'à¦¢à¦¾à¦•à¦¾à§Ÿ',\n",
       "   'à¦†à¦¸à¦¤à§‡',\n",
       "   'à¦°à¦¾à¦œà¦¿',\n",
       "   'à¦¹à¦¤à§‡',\n",
       "   'à¦¹à¦¨à¦¨à¦¿à¥¤\\n'],\n",
       "  ['à¦•à¦ à§‹à¦°',\n",
       "   'à¦…à¦§à§à¦¯à¦¬à¦¸à¦¾à§Ÿ',\n",
       "   'à¦à¦¬à¦‚',\n",
       "   'à¦…à¦•à§à¦²à¦¾à¦¨à§à¦¤',\n",
       "   'à¦ªà¦°à¦¿à¦¶à§à¦°à¦®à§‡à¦°',\n",
       "   'à¦«à¦²à§‡',\n",
       "   'à¦¬à¦¿à¦¦à§‡à¦¶à§‡',\n",
       "   'à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶à¦¿à¦¦à§‡à¦°',\n",
       "   'à¦¸à¦¾à¦«à¦²à§à¦¯à§‡à¦°',\n",
       "   'à¦¨à¦œà¦¿à¦°',\n",
       "   'à¦à¦–à¦¨',\n",
       "   'à¦­à§à¦°à¦¿',\n",
       "   'à¦­à§à¦°à¦¿à¥¤'],\n",
       "  ['à¦¦à¦¾à¦¤à¦¬à§à¦¯',\n",
       "   'à¦ªà§à¦°à¦¤à¦¿à¦·à§à¦ à¦¾à¦¨à§‡à¦°',\n",
       "   'à¦¹à¦¾à¦œà¦¾à¦°',\n",
       "   'à¦¹à¦¾à¦œà¦¾à¦°',\n",
       "   'à¦ªà¦¾à¦‰à¦¨à§à¦¡',\n",
       "   'à¦¸à¦‚à¦—à§à¦°à¦¹à§‡à¦°',\n",
       "   'à¦•à§ƒà¦¤à¦¿à¦¤à§à¦¬à§‡à¦°',\n",
       "   'à¦œà¦¨à§à¦¯',\n",
       "   'à¦¤à¦¾à¦•à§‡',\n",
       "   'à¦à¦‡',\n",
       "   'à¦¸à§à¦¬à§€à¦•à§ƒà¦¤à¦¿',\n",
       "   'à¦¦à§‡à¦“à§Ÿà¦¾',\n",
       "   'à¦¹à§Ÿà§‡à¦›à§‡à¥¤\\n'],\n",
       "  ['à¦²à¦¾à¦–',\n",
       "   'à¦²à¦¾à¦–',\n",
       "   'à¦¨à¦¾à¦°à§€à¦°',\n",
       "   'à¦¸à§à¦¬à¦¾à¦°à§à¦¥à§‡',\n",
       "   'à¦†à¦®à¦°à¦¾',\n",
       "   'à¦…à¦¬à¦¶à§à¦¯à¦‡',\n",
       "   'à¦†à¦®à¦¾à¦¦à§‡à¦°',\n",
       "   'à¦…à¦­à¦¿à¦¨à§à¦¨',\n",
       "   'à¦¸à¦‚à¦¸à§à¦•à§ƒà¦¤à¦¿,',\n",
       "   'à¦à¦¤à¦¿à¦¹à§à¦¯',\n",
       "   'à¦à¦¬à¦‚',\n",
       "   'à¦®à§‚à¦²à§à¦¯à¦¬à§‹à¦§',\n",
       "   'à¦¨à¦¿à§Ÿà§‡',\n",
       "   'à¦à¦•à¦¤à§à¦°à§‡',\n",
       "   'à¦•à¦¾à¦œ',\n",
       "   'à¦•à¦°à¦¤à§‡',\n",
       "   'à¦¹à¦¬à§‡à¥¤â€™'],\n",
       "  ['à¦¸à¦®à§à¦­à§€à¦°à§‡à¦°',\n",
       "   'à¦¬à¦¿à¦°à§à¦¦à§à¦§à§‡',\n",
       "   'à§¨à§­à§®',\n",
       "   'à¦ªà¦¾à¦¤à¦¾à¦°',\n",
       "   'à¦šà¦¾à¦°à§à¦œà¦¶à¦¿à¦Ÿ',\n",
       "   'à¦ªà§‡à¦¶',\n",
       "   'à¦•à¦°à¦¾à¦°',\n",
       "   'à¦•à¦¥à¦¾',\n",
       "   'à¦¥à¦¾à¦•à¦²à§‡à¦“',\n",
       "   'à¦¤à¦¾',\n",
       "   'à¦ªà§‡à¦¶',\n",
       "   'à¦•à¦°à¦¤à§‡',\n",
       "   'à¦¬à§à¦¯à¦°à§à¦¥',\n",
       "   'à¦ªà§à¦²à¦¿à¦¶à§‡à¦°',\n",
       "   'à¦—à§‹à§Ÿà§‡à¦¨à§à¦¦à¦¾',\n",
       "   'à¦¬à¦¿à¦­à¦¾à¦—à¥¤\\n'],\n",
       "  ['à§«',\n",
       "   'à¦à¦ªà§à¦°à¦¿à¦²',\n",
       "   'à§¨à§¦à§§à§¯',\n",
       "   'à§¦à§¦:à§¦à§¦',\n",
       "   '|',\n",
       "   'à¦†à¦ªà¦¡à§‡à¦Ÿ:',\n",
       "   'à§«',\n",
       "   'à¦à¦ªà§à¦°à¦¿à¦²',\n",
       "   'à§¨à§¦à§§à§¯',\n",
       "   'à§¦à§¨:à§ªà§¦\\n'],\n",
       "  ['à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦°',\n",
       "   'à¦¬à¦²à§‡',\n",
       "   'à¦¦à¦¿à¦²à§‡à¦¨',\n",
       "   'â€˜à¦­à¦¦à§à¦°à¦²à§‹à¦•à§‡à¦°',\n",
       "   'à¦–à§‡à¦²à¦¾â€™',\n",
       "   'à¦•à§à¦°à¦¿à¦•à§‡à¦Ÿà§‡',\n",
       "   'à¦à¦°',\n",
       "   'à¦šà§‡à¦¤à¦¨à¦¾à¦¬à¦¿à¦°à§‹à¦§à§€',\n",
       "   'à¦•à§‹à¦¨à§‹',\n",
       "   'à¦•à¦¿à¦›à§à¦¤à§‡',\n",
       "   'à¦›à¦¾à§œ',\n",
       "   'à¦¦à§‡à¦¬à§‡',\n",
       "   'à¦¨à¦¾',\n",
       "   'à¦†à¦‡à¦¸à¦¿à¦¸à¦¿à¥¤'],\n",
       "  ['à¦¤à¦¾à¦•à§‡',\n",
       "   'à¦‰à¦¦à§à¦§à¦¾à¦°',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¤à¦¾à¦°à¦•à§‡à¦¶à§à¦¬à¦°',\n",
       "   'à¦—à§à¦°à¦¾à¦®à§€à¦£',\n",
       "   'à¦¹à¦¾à¦¸à¦ªà¦¾à¦¤à¦¾à¦²à§‡',\n",
       "   'à¦¨à¦¿à§Ÿà§‡',\n",
       "   'à¦¯à¦¾à¦“à§Ÿà¦¾',\n",
       "   'à¦¹à§Ÿà¥¤'],\n",
       "  ['à¦¤à¦¿à¦¨à¦¿',\n",
       "   'à¦¬à¦²à§‡à¦¨,',\n",
       "   'à¦®à¦¹à¦¾à¦¨',\n",
       "   'à¦†à¦²à§à¦²à¦¾à¦¹',\n",
       "   \"à¦¤à¦¾'à¦†à¦²à¦¾à¦°\",\n",
       "   'à¦¬à¦¾à¦£à§€',\n",
       "   ':',\n",
       "   'â€œà¦¤à¦¾à¦à¦°à¦¾',\n",
       "   'à¦¯à¦¾à¦¦à§‡à¦°à¦•à§‡',\n",
       "   'à¦†à¦¹à§à¦¬à¦¾à¦¨',\n",
       "   'à¦•à¦°à§‡',\n",
       "   'à¦¤à¦¾à¦°à¦¾à¦‡',\n",
       "   'à¦¤à§‹',\n",
       "   'à¦¤à¦¾à¦¦à§‡à¦°',\n",
       "   'à¦ªà§à¦°à¦¤à¦¿à¦ªà¦¾à¦²à¦•à§‡à¦°',\n",
       "   'à¦¨à§ˆà¦•à¦Ÿà¦¾',\n",
       "   'à¦²à¦¾à¦­à§‡à¦°',\n",
       "   'à¦‰à¦ªà¦¾à¦¯à¦¼',\n",
       "   'à¦–à§‹à¦œ',\n",
       "   'à¦•à¦°à§‡\"-',\n",
       "   '(à¦¸à§‚à¦°à¦¾',\n",
       "   'à¦†à¦²',\n",
       "   'à¦‡à¦¸à¦°à¦¾',\n",
       "   'à§§à§­:à§«à§­)',\n",
       "   'à¦à¦°',\n",
       "   'à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾à¦¯à¦¼',\n",
       "   'à¦¬à¦²à§‡à¦¨,',\n",
       "   'à¦à¦•à¦¦à¦¾',\n",
       "   'à¦à¦•à¦¦à¦²',\n",
       "   'à¦œà¦¿à¦¨',\n",
       "   'à¦‡à¦¸à¦²à¦¾à¦®',\n",
       "   'à¦—à§à¦°à¦¹à¦£',\n",
       "   'à¦•à¦°à¦²à§‹à¥¤',\n",
       "   '(à¦à¦•à¦¦à¦²',\n",
       "   'à¦®à¦¾à¦¨à§à¦·)',\n",
       "   'à¦¤à¦¾à¦¦à§‡à¦°',\n",
       "   '(à¦œà¦¿à¦¨à¦¦à§‡à¦°)',\n",
       "   'à¦ªà§‚à¦œà¦¾',\n",
       "   'à¦•à¦°à¦¤à§‹à¥¤',\n",
       "   'à¦•à¦¿à¦¨à§à¦¤à§',\n",
       "   'à¦ªà§‚à¦œà¦¾à¦¯à¦¼',\n",
       "   'à¦°à¦¤',\n",
       "   'à¦',\n",
       "   'à¦²à§‹à¦•à¦—à§à¦²à§‹',\n",
       "   'à¦¤à¦¾à¦¦à§‡à¦°',\n",
       "   'à¦ªà§‚à¦œà¦¾à¦¤à§‡à¦‡',\n",
       "   'à¦…à¦Ÿà¦²',\n",
       "   'à¦¥à¦¾à¦•à¦²à¥¤',\n",
       "   'à¦…à¦¥à¦š',\n",
       "   'à¦œà¦¿à¦¨à§‡à¦°',\n",
       "   'à¦à¦•à¦¦à¦²',\n",
       "   'à¦‡à¦¸à¦²à¦¾à¦®',\n",
       "   'à¦—à§à¦°à¦¹à¦£',\n",
       "   'à¦•à¦°à§‡à¦›à§‡à¥¤',\n",
       "   '(à¦‡.à¦«à¦¾',\n",
       "   'à§­à§¨à§­à§©,',\n",
       "   'à¦‡.à¦¸à§‡',\n",
       "   'à§­à§©à§¨à§®)\\n'],\n",
       "  ['à¦¹à¦¾à¦œà¦¾à¦°',\n",
       "   'à¦¹à¦¾à¦œà¦¾à¦°',\n",
       "   'à¦¨à¦¾à¦°à§€',\n",
       "   'à¦¬à¦°à§à¦®à§€',\n",
       "   'à¦¸à§‡à¦¨à¦¾à¦¬à¦¾à¦¹à¦¿à¦¨à§€',\n",
       "   'à¦“',\n",
       "   'à¦®à¦—à¦¦à¦¸à§à¦¯à§à¦¦à§‡à¦°',\n",
       "   'à¦•à¦¾à¦›à§‡',\n",
       "   'à¦¸à¦®à§à¦­à§à¦°à¦®',\n",
       "   'à¦¹à¦¾à¦°à¦¿à§Ÿà§‡à¦›à§‡à¥¤',\n",
       "   'à¦—à¦£à¦§à¦°à§à¦·à¦£à§‡à¦°',\n",
       "   'à¦ªà¦°',\n",
       "   'à¦…à¦¨à§‡à¦•à¦•à§‡',\n",
       "   'à¦¨à¦¿à¦°à§à¦®à¦®',\n",
       "   'à¦“',\n",
       "   'à¦¨à¦¿à¦·à§à¦ à§à¦°à¦­à¦¾à¦¬à§‡',\n",
       "   'à¦¹à¦¤à§à¦¯à¦¾à¦“',\n",
       "   'à¦•à¦°à¦¾',\n",
       "   'à¦¹à§Ÿà§‡à¦›à§‡à¥¤\\n'],\n",
       "  ['à¦…à¦¨à§à¦¯à¦¾à¦¨à§à¦¯',\n",
       "   'à¦¹à§‹à¦Ÿà§‡à¦²',\n",
       "   'à¦®à¦¾à¦²à¦¿à¦•à¦¦à§‡à¦°',\n",
       "   'à¦®à¦¤à§‡,',\n",
       "   'à¦à¦‡',\n",
       "   'à¦…à¦¶à¦¾à¦¨à§à¦¤',\n",
       "   'à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦°',\n",
       "   'à¦®à¦§à§à¦¯à§‡',\n",
       "   'à¦ªà¦°à§à¦¯à¦Ÿà¦•à¦¦à§‡à¦°',\n",
       "   'à¦ªà¦¾à¦¶à§‡',\n",
       "   'à¦¥à¦¾à¦•à¦¾à¦‡',\n",
       "   'à¦¤à¦¾à¦¦à§‡à¦°',\n",
       "   'à¦•à¦°à§à¦¤à§ƒà¦¬à§à¦¯',\n",
       "   'à¦¬à¦²à§‡',\n",
       "   'à¦®à¦¨à§‡',\n",
       "   'à¦•à¦°à¦›à§‡à¦¨',\n",
       "   'à¦¤à¦¾à¦°à¦¾à¥¤\\n']],\n",
       " 'ner': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 2, 2, 1, 2, 1, 2, 0, 0, 0],\n",
       "  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 3, 0, 0, 1, 2, 0, 0, 5, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
       "  [0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5903f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(text_corpus['ner']), len(text_corpus['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42117217",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_corpus['ner'])):\n",
    "    (j, k) = (len(text_corpus['words'][i]), len(text_corpus['ner'][i]))\n",
    "    if j > k:\n",
    "        for _ in range(j - k):\n",
    "            text_corpus['ner'][i].append(0)\n",
    "    elif j < k :\n",
    "        text_corpus['ner'][i] = text_corpus['ner'][i][0 : k - (k - j)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3639f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_anno_data = Dataset.from_dict(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "849fb3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_anno_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33c2e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on validation dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 1180.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "manual_anno_data = manual_anno_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "974f583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_manual_anno = best_model.evaluate(manual_anno_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "587b9463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0887410044670105,\n",
       " 'eval_LOC_precision': 0.8,\n",
       " 'eval_LOC_recall': 1.0,\n",
       " 'eval_LOC_f1': 0.888888888888889,\n",
       " 'eval_LOC_number': 4,\n",
       " 'eval_ORG_precision': 0.4,\n",
       " 'eval_ORG_recall': 1.0,\n",
       " 'eval_ORG_f1': 0.5714285714285715,\n",
       " 'eval_ORG_number': 2,\n",
       " 'eval_PER_precision': 0.9333333333333333,\n",
       " 'eval_PER_recall': 0.875,\n",
       " 'eval_PER_f1': 0.9032258064516129,\n",
       " 'eval_PER_number': 16,\n",
       " 'eval_overall_precision': 0.8,\n",
       " 'eval_overall_recall': 0.9090909090909091,\n",
       " 'eval_overall_f1': 0.8510638297872342,\n",
       " 'eval_overall_accuracy': 0.9792207792207792,\n",
       " 'eval_runtime': 0.2025,\n",
       " 'eval_samples_per_second': 123.481,\n",
       " 'eval_steps_per_second': 4.939,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_manual_anno"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
