{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6019965",
   "metadata": {},
   "source": [
    "### Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9d74b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import json\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cda06593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9437c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1a0f1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Selecting the device\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850063b0",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95cfb142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# IndicBERT\n",
    "num_labels = 9\n",
    "text_name = \"words\"\n",
    "label_name = \"ner\"\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetunning_task = 'ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd591d",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "450e5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_dict = {\n",
    "    'O' : 0,\n",
    "    'B-PER' : 1,\n",
    "    'I-PER' : 2,\n",
    "    'B-ORG' : 3,\n",
    "    'I-ORG' : 4,\n",
    "    'B-LOC' : 5,\n",
    "    'I-LOC' : 6,\n",
    "    'B-MISC' : 7,\n",
    "    'I-MISC' : 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "864b515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_label = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afdf0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset( file_path, text_name = text_name, label_name = label_name, dataset_type = None, \n",
    "                 num_samples_to_take = None ):\n",
    "    \n",
    "    data_dir = { text_name : [ ], label_name : [ ] }\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data_dir[text_name].append(json.loads(line)[text_name])\n",
    "            data_dir[label_name].append( [ label_to_id_dict[i] for i in ( json.loads(line)[label_name] ) ] )\n",
    "    if dataset_type == 'train':\n",
    "        # For sampling the initial 20000 samples\n",
    "        data_dir[text_name] = data_dir[text_name][0:num_samples_to_take]\n",
    "        data_dir[label_name] = data_dir[label_name][ 0:num_samples_to_take]\n",
    "    data = Dataset.from_dict(data_dir)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28ad1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = make_dataset(\"./bn_IndicNER_v1.0/bn_train.json\", dataset_type = \"train\", num_samples_to_take=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8ecb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = make_dataset(\"./bn_IndicNER_v1.0/bn_val.json\", num_samples_to_take=100)\n",
    "test_data = make_dataset(\"./bn_IndicNER_v1.0/bn_test.json\", num_samples_to_take=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b078ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "577fab30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 4859\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7701999",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = \"max_length\"\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the text and match the target label with the text token\n",
    "    Input: A batch of sentence\n",
    "        A dict:\n",
    "            'words': A list of sentences denoted as a list of words\n",
    "                        Desired Input to the model\n",
    "            'ner': A list of desired labels\n",
    "    Output: Tokenized Sentence\n",
    "        A dict: dict:\n",
    "            'words': A list of sentences denoted as a list of words\n",
    "                        Desired Input to the model\n",
    "            'ner': A list of desired labels\n",
    "            'input_ids': Id of the tokenized words\n",
    "                            A list of sentences denoted as \n",
    "                            a list of Id s of the consitituted word tokens\n",
    "                            # Input to the Transformer model\n",
    "            'attention_masks': A binary list\n",
    "                                1 indicates the text token, model will attend to\n",
    "                                0 indicates the padding token and special token, the model will not attend to.\n",
    "            'labels': A list of numbers\n",
    "                        Denting the target ground truth label\n",
    "                        generated from the 'ner' field of Input\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_name]):\n",
    "        \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dc0ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on train dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:05<00:00, 3371.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c833e947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the toenized data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9544669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on validation dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4859/4859 [00:01<00:00, 3427.44 examples/s]\n",
      "Running tokenizer on test dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 607/607 [00:00<00:00, 3391.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_data = val_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on test dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fafecd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27872efd",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b724219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_2_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_2_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfb14f",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04876b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(batch_size, lr , model, train_data = train_data, val_data = val_data,\n",
    "                  tokenizer = tokenizer, data_collator = data_collator, compute_metrics = compute_metrics):\n",
    "                    \n",
    "    \n",
    "    \n",
    "    # Setting the TrainingArguments\n",
    "    args=TrainingArguments(\n",
    "        output_dir='output_dir',\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate = lr,\n",
    "        num_train_epochs = 3 # As asked in the question\n",
    "        )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        args=args,\n",
    "    )\n",
    "    \n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    eval_metric = trainer.evaluate(val_data)\n",
    "    \n",
    "    return (trainer, train_result, eval_metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beacc31",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85ffea",
   "metadata": {},
   "source": [
    "We have tuned the batch size and learning-rate as two are the most important hyper-parameters. \n",
    "Batch Size: Larger Batch size might result in a smoother convergence during Gradient descent, with a huge cost of calculating the gradients. Whereas smaller batch size might result ina more haphazard convergence but each step of Gradient Descent is fast. Therefore a we need to fine tune the optimum.\n",
    "\n",
    "Learning Rate: A Higher Learning Rate indicates larger step, which might lead the model to go in bad optima, and lower earning rate might not help the model to converge.\n",
    "\n",
    "We use a random sapling approach and done only 3 experiments due to limited resources for Hyper-parameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "184bf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_search():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    tunable_hyper_param = {'batch_size' : [8, 16, 32],\n",
    "                      'lr': [1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "    batch_size = tunable_hyper_param['batch_size'][random.randint(0,2)] \n",
    "                # Generating a random number between 0 and 2 (both included)\n",
    "    lr = tunable_hyper_param['lr'][random.randint(0,3)]\n",
    "                # Generating a random number between 0 and 2 (both included)\n",
    "    \n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ac40b",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40ee0878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "8 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 07:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "(trainer, train_result, eval_metric, batch_size, lr) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d554c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 8, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n",
      "{'eval_loss': 0.7926539778709412, 'eval_LOC_precision': 0.0, 'eval_LOC_recall': 0.0, 'eval_LOC_f1': 0.0, 'eval_LOC_number': 2811, 'eval_ORG_precision': 0.0, 'eval_ORG_recall': 0.0, 'eval_ORG_f1': 0.0, 'eval_ORG_number': 1751, 'eval_PER_precision': 0.0, 'eval_PER_recall': 0.0, 'eval_PER_f1': 0.0, 'eval_PER_number': 3698, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.8187221589143272, 'eval_runtime': 16.9598, 'eval_samples_per_second': 286.501, 'eval_steps_per_second': 8.962, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size, lr))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "print(eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b4c3c0",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b180e713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "32 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 06:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "(trainer_2, train_result_2, eval_metric_2, batch_size_2, lr_2) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0e91a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 32, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7922132611274719,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187221589143272,\n",
       " 'eval_runtime': 17.2603,\n",
       " 'eval_samples_per_second': 281.513,\n",
       " 'eval_steps_per_second': 8.806,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_2, lr_2))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1fada4",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7eecd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "32 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 06:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(trainer_3, train_result_3, eval_metric_3, batch_size_3, lr_3) = hyper_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75c4a66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 32, and Learning Rate = 0.01 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7922132611274719,\n",
       " 'eval_LOC_precision': 0.0,\n",
       " 'eval_LOC_recall': 0.0,\n",
       " 'eval_LOC_f1': 0.0,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.0,\n",
       " 'eval_ORG_recall': 0.0,\n",
       " 'eval_ORG_f1': 0.0,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.0,\n",
       " 'eval_PER_recall': 0.0,\n",
       " 'eval_PER_f1': 0.0,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.0,\n",
       " 'eval_overall_recall': 0.0,\n",
       " 'eval_overall_f1': 0.0,\n",
       " 'eval_overall_accuracy': 0.8187221589143272,\n",
       " 'eval_runtime': 17.0933,\n",
       " 'eval_samples_per_second': 284.264,\n",
       " 'eval_steps_per_second': 8.892,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_3, lr_3))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5220524",
   "metadata": {},
   "source": [
    "##### Hyper-parameter Search Experiment with lower Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64e1968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_setting():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    batch_size = 8\n",
    "    lr = 1e-5\n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a95cf90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "8 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 07:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.656700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.409200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='949' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 9:46:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(trainer_4, train_result_4, eval_metric_4, batch_size_4, lr_4) = hyper_param_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bd304a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 8, and Learning Rate = 1e-05 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4211013615131378,\n",
       " 'eval_LOC_precision': 0.49778172138420584,\n",
       " 'eval_LOC_recall': 0.3991462113127001,\n",
       " 'eval_LOC_f1': 0.443040473840079,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.2852233676975945,\n",
       " 'eval_ORG_recall': 0.14220445459737294,\n",
       " 'eval_ORG_f1': 0.18978658536585366,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.560645347162201,\n",
       " 'eval_PER_recall': 0.5262303948080044,\n",
       " 'eval_PER_f1': 0.5428930115776259,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.5027280994240679,\n",
       " 'eval_overall_recall': 0.40157384987893463,\n",
       " 'eval_overall_f1': 0.44649347153048863,\n",
       " 'eval_overall_accuracy': 0.8746115197347974,\n",
       " 'eval_runtime': 17.2133,\n",
       " 'eval_samples_per_second': 282.282,\n",
       " 'eval_steps_per_second': 8.83,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_4, lr_4))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995536e",
   "metadata": {},
   "source": [
    "##### Hyper-parameter search experiment with lower learning rate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0d4bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_param_setting_2():\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
    "    model=model.to(device)\n",
    "    \n",
    "    batch_size = 16\n",
    "    lr = 1e-5\n",
    "    print('Batch size Learning Rate')\n",
    "    print(batch_size, lr)\n",
    "    \n",
    "    (trainer, train_result, eval_metric) = training_model(batch_size, lr, model)\n",
    "    \n",
    "    return  (trainer, train_result, eval_metric, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61eafd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size Learning Rate\n",
      "16 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 06:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.618200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Batch Size = 16, and Learning Rate = 1e-05 :\n",
      "The Evaluation Metric on the validation Data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4501913785934448,\n",
       " 'eval_LOC_precision': 0.4909437559580553,\n",
       " 'eval_LOC_recall': 0.3664176449662042,\n",
       " 'eval_LOC_f1': 0.4196374006926054,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.2288135593220339,\n",
       " 'eval_ORG_recall': 0.09251856082238721,\n",
       " 'eval_ORG_f1': 0.13176087840585604,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.550876114355979,\n",
       " 'eval_PER_recall': 0.48458626284478096,\n",
       " 'eval_PER_f1': 0.5156092648539778,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.49249050998514604,\n",
       " 'eval_overall_recall': 0.3612590799031477,\n",
       " 'eval_overall_f1': 0.416788881905161,\n",
       " 'eval_overall_accuracy': 0.8689785558893608,\n",
       " 'eval_runtime': 17.3408,\n",
       " 'eval_samples_per_second': 280.206,\n",
       " 'eval_steps_per_second': 8.765,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainer_5, train_result_5, eval_metric_5, batch_size_5, lr_5) = hyper_param_setting_2()\n",
    "print ('For Batch Size = {}, and Learning Rate = {} :'.format(batch_size_5, lr_5))\n",
    "print('The Evaluation Metric on the validation Data: ')\n",
    "eval_metric_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ddd74",
   "metadata": {},
   "source": [
    "### Caculating the Macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "890d75b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "best_model = trainer_4\n",
    "test_metric = best_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5b0a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.model.save_pretrained(\"./IndicBERT_best\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4cfffcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3632481098175049,\n",
       " 'eval_LOC_precision': 0.5439330543933054,\n",
       " 'eval_LOC_recall': 0.39274924471299094,\n",
       " 'eval_LOC_f1': 0.45614035087719296,\n",
       " 'eval_LOC_number': 331,\n",
       " 'eval_ORG_precision': 0.42990654205607476,\n",
       " 'eval_ORG_recall': 0.2222222222222222,\n",
       " 'eval_ORG_f1': 0.2929936305732484,\n",
       " 'eval_ORG_number': 207,\n",
       " 'eval_PER_precision': 0.6148491879350348,\n",
       " 'eval_PER_recall': 0.5773420479302832,\n",
       " 'eval_PER_f1': 0.595505617977528,\n",
       " 'eval_PER_number': 459,\n",
       " 'eval_overall_precision': 0.5675675675675675,\n",
       " 'eval_overall_recall': 0.44232698094282846,\n",
       " 'eval_overall_f1': 0.49718151071025923,\n",
       " 'eval_overall_accuracy': 0.8896598794221363,\n",
       " 'eval_runtime': 4.0598,\n",
       " 'eval_samples_per_second': 149.513,\n",
       " 'eval_steps_per_second': 4.68,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a37b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4211013615131378,\n",
       " 'eval_LOC_precision': 0.49778172138420584,\n",
       " 'eval_LOC_recall': 0.3991462113127001,\n",
       " 'eval_LOC_f1': 0.443040473840079,\n",
       " 'eval_LOC_number': 2811,\n",
       " 'eval_ORG_precision': 0.2852233676975945,\n",
       " 'eval_ORG_recall': 0.14220445459737294,\n",
       " 'eval_ORG_f1': 0.18978658536585366,\n",
       " 'eval_ORG_number': 1751,\n",
       " 'eval_PER_precision': 0.560645347162201,\n",
       " 'eval_PER_recall': 0.5262303948080044,\n",
       " 'eval_PER_f1': 0.5428930115776259,\n",
       " 'eval_PER_number': 3698,\n",
       " 'eval_overall_precision': 0.5027280994240679,\n",
       " 'eval_overall_recall': 0.40157384987893463,\n",
       " 'eval_overall_f1': 0.44649347153048863,\n",
       " 'eval_overall_accuracy': 0.8746115197347974,\n",
       " 'eval_runtime': 31.6466,\n",
       " 'eval_samples_per_second': 153.539,\n",
       " 'eval_steps_per_second': 4.803,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric = best_model.evaluate(val_data)\n",
    "val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89965450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3800722658634186,\n",
       " 'eval_LOC_precision': 0.5349235212322173,\n",
       " 'eval_LOC_recall': 0.434189963535336,\n",
       " 'eval_LOC_f1': 0.4793214165907893,\n",
       " 'eval_LOC_number': 11518,\n",
       " 'eval_ORG_precision': 0.33901277875219243,\n",
       " 'eval_ORG_recall': 0.18859771396710343,\n",
       " 'eval_ORG_f1': 0.24236453201970445,\n",
       " 'eval_ORG_number': 7174,\n",
       " 'eval_PER_precision': 0.591568225224588,\n",
       " 'eval_PER_recall': 0.5569021775321302,\n",
       " 'eval_PER_f1': 0.5737120120738148,\n",
       " 'eval_PER_number': 15017,\n",
       " 'eval_overall_precision': 0.5356116024311243,\n",
       " 'eval_overall_recall': 0.43658963481562785,\n",
       " 'eval_overall_f1': 0.48105775831072467,\n",
       " 'eval_overall_accuracy': 0.8876350736708247,\n",
       " 'eval_runtime': 114.6004,\n",
       " 'eval_samples_per_second': 174.519,\n",
       " 'eval_steps_per_second': 5.454,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metric = best_model.evaluate(train_data)\n",
    "train_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d6d05",
   "metadata": {},
   "source": [
    "### Load the Manually Annotated Data and Calc the Macro-F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "003d0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_corpus_label_from_manual_anno(text):\n",
    "    \"\"\"\n",
    "    Modify the annotated label, such that model can use it as Tags\n",
    "    \"\"\"\n",
    "    text_1 = text.split(' ')\n",
    "    new_text = []\n",
    "    new_id = []\n",
    "    for word in text_1:\n",
    "        if word == '[' or word == ']' or word == ',' or word == '\"' or word == '\\n' or word == ' ' or word == '':\n",
    "            pass\n",
    "        else:\n",
    "            n_w = ''\n",
    "            for i in word:\n",
    "                if i == '[' or i == ']' or i == ',' or i == '\"' or i == '\\n' or i == '\\'':\n",
    "                    pass\n",
    "                else:\n",
    "                    n_w = n_w + i\n",
    "            if n_w != '':\n",
    "                new_text.append(n_w)\n",
    "                new_id.append(label_to_id_dict[n_w])\n",
    "    return (new_id, new_text)\n",
    "\n",
    "\n",
    "i = 0\n",
    "text_corpus = {'words':[],\n",
    "              'ner' : []}\n",
    "with open(\"annotated_text.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if i % 3 == 0:\n",
    "            text = line\n",
    "            text_1 = text.split(\" \")[1:]\n",
    "            if text_1[-1] == '\\n':\n",
    "                text_1 = text_1[0:-1]\n",
    "            text_corpus['words'].append(text_1)\n",
    "        elif i % 3 == 1:\n",
    "            label = line\n",
    "            ( new_label_id, new_label ) = form_corpus_label_from_manual_anno(label)\n",
    "            text_corpus['ner'].append(new_label_id)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8763fc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': [['রাত',\n",
       "   'সাড়ে',\n",
       "   'আটটাতেও',\n",
       "   'ওকে',\n",
       "   'একা',\n",
       "   'রিকশায়',\n",
       "   'ছেড়ে',\n",
       "   'দিতে',\n",
       "   'তিনি',\n",
       "   'রাজি',\n",
       "   'নন।\\n'],\n",
       "  ['একাধিক',\n",
       "   'জঙ্গি',\n",
       "   'ঘাঁটি',\n",
       "   'ধ্বংস',\n",
       "   'করে',\n",
       "   'দেওয়া',\n",
       "   'হয়েছে',\n",
       "   'বলে',\n",
       "   'দাবি',\n",
       "   'করে',\n",
       "   'সরকার।\\n'],\n",
       "  ['এ',\n",
       "   'সম্মেলনে',\n",
       "   'বিশ্বের',\n",
       "   'প্রায়',\n",
       "   'দেড়',\n",
       "   'হাজার',\n",
       "   'নারী',\n",
       "   'নেতৃত্ব',\n",
       "   'যোগদান',\n",
       "   'করেন।\\n'],\n",
       "  ['আব্দুল',\n",
       "   'মালেক',\n",
       "   'হিমু,',\n",
       "   'অপু',\n",
       "   'আলম,',\n",
       "   'দবির',\n",
       "   'মোহাম্মদ',\n",
       "   'সহ',\n",
       "   'আরো',\n",
       "   'অনেকে।\\n'],\n",
       "  ['মিথিলা',\n",
       "   'যে',\n",
       "   'অনিকের',\n",
       "   'এই',\n",
       "   'জিনিসগুলো',\n",
       "   'জানে',\n",
       "   'না',\n",
       "   'তা',\n",
       "   'নয়।',\n",
       "   'কিন্তু',\n",
       "   'সে',\n",
       "   'চায়',\n",
       "   'যে',\n",
       "   'অনিক',\n",
       "   'সব',\n",
       "   'সময়',\n",
       "   'তার',\n",
       "   'কাছে',\n",
       "   'সত্যি',\n",
       "   'কথা',\n",
       "   'বলুক।'],\n",
       "  ['লোকসভার',\n",
       "   'স্পিকার',\n",
       "   'ওম',\n",
       "   'বিড়লার',\n",
       "   'প্রস্তাবে',\n",
       "   'সম্মতি',\n",
       "   'জানিয়েছেন',\n",
       "   'সব',\n",
       "   'দলের',\n",
       "   'সাংসদরা।\\n'],\n",
       "  ['মিথিলা', 'চুপ', 'করে', 'শুনে', 'গেলেও', 'মুখে', 'কিছু', 'বলল', 'না।'],\n",
       "  ['জানা',\n",
       "   'যায়,',\n",
       "   'জগন্নাথপুর',\n",
       "   'পৌর',\n",
       "   'শহরের',\n",
       "   'ছিলিমপুর',\n",
       "   'গ্রামের',\n",
       "   'প্রয়াত',\n",
       "   'শালিসি',\n",
       "   'ব্যক্তি',\n",
       "   'হাজী',\n",
       "   'ফিরোজ',\n",
       "   'মিয়ার',\n",
       "   'বিপুল',\n",
       "   'পরিমাণ',\n",
       "   'জায়গা',\n",
       "   'সম্পত্তি',\n",
       "   'রয়েছে।'],\n",
       "  ['পুলিশ',\n",
       "   'সুপার',\n",
       "   'শ্যামল',\n",
       "   'কুমার',\n",
       "   'নাথ',\n",
       "   'জানান,',\n",
       "   'জমিসংক্রান্ত',\n",
       "   'বিষয়',\n",
       "   'নিয়ে',\n",
       "   'এই',\n",
       "   'হামলা',\n",
       "   'হয়েছে।'],\n",
       "  ['এ',\n",
       "   'ছবিতে',\n",
       "   'সলমন',\n",
       "   'খানকে',\n",
       "   'এক',\n",
       "   'সাধারণ',\n",
       "   'নাগরিকের',\n",
       "   'চরিত্রে',\n",
       "   'দেখা',\n",
       "   'যাবে।\\n'],\n",
       "  ['একাদশ',\n",
       "   'জাতীয়',\n",
       "   'সংসদ',\n",
       "   'নির্বাচনে',\n",
       "   'নির্বাচিত',\n",
       "   '২৯০',\n",
       "   'সাংসদের',\n",
       "   'পদে',\n",
       "   'থাকার',\n",
       "   'বৈধতা',\n",
       "   'নিয়ে',\n",
       "   'করা',\n",
       "   'রিটটি',\n",
       "   'সরাসরি',\n",
       "   'খারিজ',\n",
       "   'করে',\n",
       "   'দিয়েছেন',\n",
       "   'হাইকোর্ট।\\n'],\n",
       "  ['টাকা',\n",
       "   'ছিল',\n",
       "   'না',\n",
       "   'বলে',\n",
       "   'জিনিসপত্র',\n",
       "   'ফেরি',\n",
       "   'করে',\n",
       "   'বেড়ানো,',\n",
       "   'দোকান',\n",
       "   'দেওয়া,',\n",
       "   'থাকা-খাওয়ার',\n",
       "   'বিনিময়ে',\n",
       "   'নবিশি',\n",
       "   'কিংবা',\n",
       "   'সমাজের',\n",
       "   'উঁচুতলার',\n",
       "   'জন্য',\n",
       "   'সন্ন্যাসিনী',\n",
       "   'হওয়া—এসব',\n",
       "   'বাতিল',\n",
       "   'হয়ে',\n",
       "   'গেল।\\n'],\n",
       "  ['কারণ',\n",
       "   'সে',\n",
       "   'নিজে',\n",
       "   'কাল',\n",
       "   'অনিককে',\n",
       "   'শপিং',\n",
       "   'মলে',\n",
       "   'একটা',\n",
       "   'মেয়ের',\n",
       "   'সাথে',\n",
       "   'দেখেছে।'],\n",
       "  ['মেয়েটি',\n",
       "   'যাতে',\n",
       "   'বিনা',\n",
       "   'মূল্যে',\n",
       "   'লেখাপড়ার',\n",
       "   'সুযোগ',\n",
       "   'পায়,',\n",
       "   'সে',\n",
       "   'ব্যবস্থাও',\n",
       "   'সরকারকেই',\n",
       "   'করতে',\n",
       "   'হবে।\\n'],\n",
       "  ['জানা',\n",
       "   'গেছে,',\n",
       "   'বিপিএলের',\n",
       "   'উদ্বোধনী',\n",
       "   'অনুষ্ঠানে',\n",
       "   'সালমান',\n",
       "   'খান',\n",
       "   'নাকি',\n",
       "   'শুরুতে',\n",
       "   'ঢাকায়',\n",
       "   'আসতে',\n",
       "   'রাজি',\n",
       "   'হতে',\n",
       "   'হননি।\\n'],\n",
       "  ['কঠোর',\n",
       "   'অধ্যবসায়',\n",
       "   'এবং',\n",
       "   'অক্লান্ত',\n",
       "   'পরিশ্রমের',\n",
       "   'ফলে',\n",
       "   'বিদেশে',\n",
       "   'বাংলাদেশিদের',\n",
       "   'সাফল্যের',\n",
       "   'নজির',\n",
       "   'এখন',\n",
       "   'ভুরি',\n",
       "   'ভুরি।'],\n",
       "  ['দাতব্য',\n",
       "   'প্রতিষ্ঠানের',\n",
       "   'হাজার',\n",
       "   'হাজার',\n",
       "   'পাউন্ড',\n",
       "   'সংগ্রহের',\n",
       "   'কৃতিত্বের',\n",
       "   'জন্য',\n",
       "   'তাকে',\n",
       "   'এই',\n",
       "   'স্বীকৃতি',\n",
       "   'দেওয়া',\n",
       "   'হয়েছে।\\n'],\n",
       "  ['লাখ',\n",
       "   'লাখ',\n",
       "   'নারীর',\n",
       "   'স্বার্থে',\n",
       "   'আমরা',\n",
       "   'অবশ্যই',\n",
       "   'আমাদের',\n",
       "   'অভিন্ন',\n",
       "   'সংস্কৃতি,',\n",
       "   'ঐতিহ্য',\n",
       "   'এবং',\n",
       "   'মূল্যবোধ',\n",
       "   'নিয়ে',\n",
       "   'একত্রে',\n",
       "   'কাজ',\n",
       "   'করতে',\n",
       "   'হবে।’'],\n",
       "  ['সম্ভীরের',\n",
       "   'বিরুদ্ধে',\n",
       "   '২৭৮',\n",
       "   'পাতার',\n",
       "   'চার্জশিট',\n",
       "   'পেশ',\n",
       "   'করার',\n",
       "   'কথা',\n",
       "   'থাকলেও',\n",
       "   'তা',\n",
       "   'পেশ',\n",
       "   'করতে',\n",
       "   'ব্যর্থ',\n",
       "   'পুলিশের',\n",
       "   'গোয়েন্দা',\n",
       "   'বিভাগ।\\n'],\n",
       "  ['৫',\n",
       "   'এপ্রিল',\n",
       "   '২০১৯',\n",
       "   '০০:০০',\n",
       "   '|',\n",
       "   'আপডেট:',\n",
       "   '৫',\n",
       "   'এপ্রিল',\n",
       "   '২০১৯',\n",
       "   '০২:৪০\\n'],\n",
       "  ['পরিষ্কার',\n",
       "   'বলে',\n",
       "   'দিলেন',\n",
       "   '‘ভদ্রলোকের',\n",
       "   'খেলা’',\n",
       "   'ক্রিকেটে',\n",
       "   'এর',\n",
       "   'চেতনাবিরোধী',\n",
       "   'কোনো',\n",
       "   'কিছুতে',\n",
       "   'ছাড়',\n",
       "   'দেবে',\n",
       "   'না',\n",
       "   'আইসিসি।'],\n",
       "  ['তাকে',\n",
       "   'উদ্ধার',\n",
       "   'করে',\n",
       "   'তারকেশ্বর',\n",
       "   'গ্রামীণ',\n",
       "   'হাসপাতালে',\n",
       "   'নিয়ে',\n",
       "   'যাওয়া',\n",
       "   'হয়।'],\n",
       "  ['তিনি',\n",
       "   'বলেন,',\n",
       "   'মহান',\n",
       "   'আল্লাহ',\n",
       "   \"তা'আলার\",\n",
       "   'বাণী',\n",
       "   ':',\n",
       "   '“তাঁরা',\n",
       "   'যাদেরকে',\n",
       "   'আহ্বান',\n",
       "   'করে',\n",
       "   'তারাই',\n",
       "   'তো',\n",
       "   'তাদের',\n",
       "   'প্রতিপালকের',\n",
       "   'নৈকটা',\n",
       "   'লাভের',\n",
       "   'উপায়',\n",
       "   'খোজ',\n",
       "   'করে\"-',\n",
       "   '(সূরা',\n",
       "   'আল',\n",
       "   'ইসরা',\n",
       "   '১৭:৫৭)',\n",
       "   'এর',\n",
       "   'ব্যাখ্যায়',\n",
       "   'বলেন,',\n",
       "   'একদা',\n",
       "   'একদল',\n",
       "   'জিন',\n",
       "   'ইসলাম',\n",
       "   'গ্রহণ',\n",
       "   'করলো।',\n",
       "   '(একদল',\n",
       "   'মানুষ)',\n",
       "   'তাদের',\n",
       "   '(জিনদের)',\n",
       "   'পূজা',\n",
       "   'করতো।',\n",
       "   'কিন্তু',\n",
       "   'পূজায়',\n",
       "   'রত',\n",
       "   'এ',\n",
       "   'লোকগুলো',\n",
       "   'তাদের',\n",
       "   'পূজাতেই',\n",
       "   'অটল',\n",
       "   'থাকল।',\n",
       "   'অথচ',\n",
       "   'জিনের',\n",
       "   'একদল',\n",
       "   'ইসলাম',\n",
       "   'গ্রহণ',\n",
       "   'করেছে।',\n",
       "   '(ই.ফা',\n",
       "   '৭২৭৩,',\n",
       "   'ই.সে',\n",
       "   '৭৩২৮)\\n'],\n",
       "  ['হাজার',\n",
       "   'হাজার',\n",
       "   'নারী',\n",
       "   'বর্মী',\n",
       "   'সেনাবাহিনী',\n",
       "   'ও',\n",
       "   'মগদস্যুদের',\n",
       "   'কাছে',\n",
       "   'সম্ভ্রম',\n",
       "   'হারিয়েছে।',\n",
       "   'গণধর্ষণের',\n",
       "   'পর',\n",
       "   'অনেককে',\n",
       "   'নির্মম',\n",
       "   'ও',\n",
       "   'নিষ্ঠুরভাবে',\n",
       "   'হত্যাও',\n",
       "   'করা',\n",
       "   'হয়েছে।\\n'],\n",
       "  ['অন্যান্য',\n",
       "   'হোটেল',\n",
       "   'মালিকদের',\n",
       "   'মতে,',\n",
       "   'এই',\n",
       "   'অশান্ত',\n",
       "   'পরিস্থিতির',\n",
       "   'মধ্যে',\n",
       "   'পর্যটকদের',\n",
       "   'পাশে',\n",
       "   'থাকাই',\n",
       "   'তাদের',\n",
       "   'কর্তৃব্য',\n",
       "   'বলে',\n",
       "   'মনে',\n",
       "   'করছেন',\n",
       "   'তারা।\\n']],\n",
       " 'ner': [[0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 7, 8, 0, 0, 0, 0],\n",
       "  [1, 2, 2, 1, 2, 1, 2, 0, 0, 0],\n",
       "  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "  [7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 3, 0, 0, 1, 2, 0, 0, 5, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [7, 8, 8, 8, 0, 0, 7, 8, 8, 8],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
       "  [0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   2,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   7,\n",
       "   0,\n",
       "   7],\n",
       "  [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "53c11e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(text_corpus['ner']), len(text_corpus['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bc727f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_corpus['ner'])):\n",
    "    (j, k) = (len(text_corpus['words'][i]), len(text_corpus['ner'][i]))\n",
    "    if j > k:\n",
    "        for _ in range(j - k):\n",
    "            text_corpus['ner'][i].append(0)\n",
    "    elif j < k :\n",
    "        text_corpus['ner'][i] = text_corpus['ner'][i][0 : k - (k - j)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "382f585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_anno_data = Dataset.from_dict(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97a4f351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['words', 'ner'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_anno_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "05895f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on validation dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 1290.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "manual_anno_data = manual_anno_data.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "49ee8d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/user/anaconda3/envs/env1/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result_manual_anno = best_model.evaluate(manual_anno_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8d32a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8164288401603699,\n",
       " 'eval_LOC_precision': 1.0,\n",
       " 'eval_LOC_recall': 0.5,\n",
       " 'eval_LOC_f1': 0.6666666666666666,\n",
       " 'eval_LOC_number': 4,\n",
       " 'eval_MISC_precision': 0.0,\n",
       " 'eval_MISC_recall': 0.0,\n",
       " 'eval_MISC_f1': 0.0,\n",
       " 'eval_MISC_number': 20,\n",
       " 'eval_ORG_precision': 1.0,\n",
       " 'eval_ORG_recall': 0.5,\n",
       " 'eval_ORG_f1': 0.6666666666666666,\n",
       " 'eval_ORG_number': 2,\n",
       " 'eval_PER_precision': 0.1875,\n",
       " 'eval_PER_recall': 0.1875,\n",
       " 'eval_PER_f1': 0.1875,\n",
       " 'eval_PER_number': 16,\n",
       " 'eval_overall_precision': 0.3157894736842105,\n",
       " 'eval_overall_recall': 0.14285714285714285,\n",
       " 'eval_overall_f1': 0.19672131147540983,\n",
       " 'eval_overall_accuracy': 0.8363636363636363,\n",
       " 'eval_runtime': 0.1547,\n",
       " 'eval_samples_per_second': 161.627,\n",
       " 'eval_steps_per_second': 6.465,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_manual_anno"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
